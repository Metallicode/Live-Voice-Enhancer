# Real-Time Voice Enhancer & Vocoder (Assistive Speech DSP)

This project is a **real-time Python audio processing pipeline** designed to help improve the intelligibility of weak or impaired speech (e.g. vocal cord paralysis) in noisy or non-ideal environments.

It processes live microphone input and outputs a clearer, louder, and optionally vocoded voice through speakers or headphones with **low latency**.

This is **assistive DSP**, not a medical device.

---

## Features

- ðŸŽ™ **Live microphone input â†’ speaker output**
- ðŸ”Š **Upward compressor** for very quiet voices
- ðŸšª **Smoothed noise gate** (no harsh chopping)
- ðŸ§  **Adaptive spectral noise reduction**
  - Learns the noise profile in real time
- ðŸŽš **Speech-focused EQ**
  - High-pass filter
  - Presence boost (2â€“4 kHz)
  - Mild high-frequency shelf
- ðŸ¤– **Classic multi-band channel vocoder**
  - Noise carrier
  - Log-spaced frequency bands
  - Adjustable mix with natural voice
- ðŸ§± **Limiter** to prevent clipping

Designed to be:
- Hackable
- Educational
- Extendable (ASR â†’ TTS, pitch shifting, formant work, etc.)

---

## Requirements

- Python **3.9+**
- PortAudio (system dependency)

### Python packages

```bash
pip install sounddevice numpy
```





# STT â†’ TTS Assistive Voice Proxy

This project is a **simple speech-to-text â†’ text-to-speech (STT â†’ TTS)** loop in Python, designed as a prototype â€œvoice proxyâ€ for people with weak or impaired speech (e.g. vocal cord paralysis).

The idea:

1. The user speaks into a microphone.
2. A speech recognition model (Whisper) converts the audio to text.
3. A TTS engine speaks the text back with a **clear, loud synthetic voice**.

Itâ€™s not real-time syllable-by-syllable, but works well for **short phrases** and is much more intelligible than a very weak, breathy voice.

> âš ï¸ This is an experimental assistive tool, not a medical device.

---

## Features

- ðŸŽ™ **Press-to-talk recording** from the microphone
- ðŸ§  **Whisper-based speech recognition** (local model)
- ðŸ—£ **On-device text-to-speech** via `pyttsx3`
- ðŸ” Simple loop:
  - Press Enter â†’ record
  - Whisper transcribes
  - TTS speaks the recognized text
- ðŸ§© Easy to customize:
  - Recording length
  - Whisper model size (`tiny`, `base`, `small`â€¦)
  - TTS voice and speaking rate

---

## Requirements

### System

- Python **3.9+**
- A working microphone
- Speakers or headphones
- `ffmpeg` installed and on your PATH (required by Whisper)

Examples:

- **Debian/Ubuntu:**
  ```bash
  sudo apt install ffmpeg

```
pip install sounddevice numpy openai-whisper pyttsx3
```





# Hebrew Speech-to-Text (STT) with faster-whisper

This project provides a **simple speech-to-text pipeline** using  
[`faster-whisper`](https://github.com/SYSTRAN/faster-whisper) and a **Hebrew-optimized Whisper model**:

> **ivrit-ai/whisper-large-v3-ct2**
>
> https://huggingface.co/ivrit-ai/models

It is intended as a foundation for **assistive speech applications**, where spoken Hebrew is converted into clear, machine-readable text (and later TTS).

---

## Requirements

### System
- Ubuntu 20.04+
- A working microphone
- Python **3.11** (recommended)
- Internet connection (model downloads once)

### Python packages
- `faster-whisper`
- `soundfile`
- `numpy`
- `sounddevice` (for mic input, optional)

---

## Installation

### 1. Create and activate a Python 3.11 virtual environment

```bash
python3.11 -m venv venv311
source venv311/bin/activate

